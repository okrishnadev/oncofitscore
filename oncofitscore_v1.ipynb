{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import sys\n",
    "\n",
    "classes = []\n",
    "data = []\n",
    "names = []\n",
    "fil=open('complex.csv')\n",
    "x=0\n",
    "for lin in fil.readlines():\n",
    "    if(x==0):\n",
    "        x=1\n",
    "        header = lin.strip().split(\",\")[1:-2]\n",
    "    else:\n",
    "        flds = lin.strip().split(\",\")\n",
    "        classes.append(flds[-2])\n",
    "        data.append(flds[1:-3])\n",
    "        names.append(flds[0])\n",
    "fil.close()\n",
    "\n",
    "\n",
    "data = np.array(data).astype(np.float)\n",
    "#classes = np.array(classes).astype(np.float)\n",
    "data = MinMaxScaler().fit_transform(data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, classes, test_size=0.2)\n",
    "\n",
    "data = X_train\n",
    "classes = y_train\n",
    "\n",
    "orig_data = X_test\n",
    "orig_classes = y_test\n",
    "\n",
    "ros = RandomOverSampler()\n",
    "X_resampled, y_resampled = ros.fit_sample(data, classes)\n",
    "\n",
    "#print classes\n",
    "\n",
    "data = X_resampled\n",
    "classes = y_resampled\n",
    "#data = RobustScaler().fit_transform(data)\n",
    "\n",
    "#for c in classes:\n",
    "#    print c\n",
    "# SVM params\n",
    "print (\"SVM predictions\")\n",
    "clf = svm.SVC(kernel='rbf',gamma=1000.0, C=100.0,max_iter=500)\n",
    "clf.fit(data, classes)  \n",
    "svm_pred = clf.predict(orig_data)\n",
    "cv_score = cross_val_score(clf, data, classes, scoring='accuracy',cv=5)\n",
    "print (cv_score)\n",
    "print (str(np.mean(cv_score))+\"\\t\"+str(np.std(cv_score)))\n",
    "grid = GridSearchCV(svm.SVC(),param_grid={'C':[10, 100, 1000,10000],'gamma':[10.0,100.0,1000.0],'kernel':['linear','rbf','poly'],'max_iter':[100,500,1000],'degree':[2,3,4,5]},scoring='accuracy',cv=5)\n",
    "grid.fit(data,classes)\n",
    "print(grid.best_params_)\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "\n",
    "\n",
    "# Neural network\n",
    "print (\"Neural net predictions\")\n",
    "clf = MLPClassifier(solver='adam', alpha=0.1, hidden_layer_sizes=(125, 5),max_iter=1000)\n",
    "clf.fit(data, classes)\n",
    "cnn_pred = clf.predict(orig_data)\n",
    "cv_score = cross_val_score(clf, data, classes, scoring='accuracy',cv=5)\n",
    "print (cv_score)\n",
    "print (str(np.mean(cv_score))+\"\\t\"+str(np.std(cv_score)))\n",
    "grid = GridSearchCV(MLPClassifier(),param_grid={'solver':['adam'],'alpha':[0.1,0.2,0.5],'max_iter':[500,1000,5000],'hidden_layer_sizes':[(100,10),(125,10),(200,10),(100,5),(125,5),(200,5)]},scoring='accuracy',cv=5)\n",
    "grid.fit(data,classes)\n",
    "print(grid.best_params_)\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "\n",
    "# Random Forest\n",
    "print (\"Random Forest predictions\")\n",
    "clf = RandomForestClassifier(n_estimators=100, max_features=8)\n",
    "clf.fit(data, classes)\n",
    "rf_pred = clf.predict(orig_data)\n",
    "cv_score = cross_val_score(clf, data, classes, scoring='accuracy',cv=5)\n",
    "print (cv_score)\n",
    "print (str(np.mean(cv_score))+\"\\t\"+str(np.std(cv_score)))\n",
    "grid = GridSearchCV(RandomForestClassifier(),param_grid={'max_features':[8,9, 10,15,20,25,30,40],'n_estimators':[100,500,1000]},scoring='accuracy',cv=5)\n",
    "grid.fit(data,classes)\n",
    "print(grid.best_params_)\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "#print('RF feature_importances:')\n",
    "#for i, j in zip(header, clf.feature_importances_): print(i,j)\n",
    "\n",
    "# Gradient boosting tree\n",
    "print (\"Gradient Boosting Tree predictions\")\n",
    "clf = GradientBoostingClassifier(n_estimators=50, learning_rate=1.0,max_features=40)\n",
    "clf.fit(data, classes)\n",
    "gbt_pred = clf.predict(orig_data)\n",
    "cv_score = cross_val_score(clf, data, classes, scoring='accuracy',cv=5)\n",
    "print (cv_score)\n",
    "print (str(np.mean(cv_score))+\"\\t\"+str(np.std(cv_score)))\n",
    "grid = GridSearchCV(GradientBoostingClassifier(),param_grid={'max_features':[8,9,10,20,25,30,40],'n_estimators':[50,100,500],'learning_rate':[0.1,1.0,2.0,5.0]},scoring='accuracy',cv=5)\n",
    "grid.fit(data,classes)\n",
    "print(grid.best_params_)\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "\n",
    "\n",
    "# AdaBoost\n",
    "print (\"AdaBoost Tree predictions\")\n",
    "clf = AdaBoostClassifier(n_estimators=500,learning_rate=1.0)\n",
    "clf.fit(data, classes)\n",
    "ada_pred = clf.predict(orig_data)\n",
    "cv_score = cross_val_score(clf, data, classes, scoring='accuracy',cv=5)\n",
    "print (cv_score)\n",
    "print (str(np.mean(cv_score))+\"\\t\"+str(np.std(cv_score)))\n",
    "grid = GridSearchCV(AdaBoostClassifier(),param_grid={'n_estimators':[50,100,500,1000],'learning_rate':[0.1,1.0,2.0,3.0,5.0]},scoring='accuracy',cv=5)\n",
    "grid.fit(data,classes)\n",
    "print(grid.best_params_)\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "\n",
    "x=0\n",
    "for gen in svm_pred:\n",
    "    print (names[x]+\"\\t\\t\"+str(svm_pred[x])+\"\\t\"+str(cnn_pred[x])+\"\\t\"+str(rf_pred[x])+\"\\t\"+str(gbt_pred[x])+\"\\t\"+str(ada_pred[x])+\"\\t\"+orig_classes[x]\n",
    "    ,x=x+1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
