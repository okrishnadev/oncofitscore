{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install imblearn\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score as coh_kap\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import sys\n",
    "\n",
    "classes = []\n",
    "data = []\n",
    "names = []\n",
    "fil=open(\"complex.csv\",\"r\")\n",
    "x=0\n",
    "for lin in fil.readlines():\n",
    "    if(x==0):\n",
    "        x=1\n",
    "        header = lin.strip().split(\",\")[1:-2]\n",
    "    else:\n",
    "        flds = lin.strip().split(\",\")\n",
    "        classes.append(flds[-1])\n",
    "        data.append(flds[1:-4]+[flds[-3]])\n",
    "        names.append(flds[0])\n",
    "fil.close()\n",
    "\n",
    "\n",
    "data = np.array(data).astype(np.float)\n",
    "#classes = np.array(classes).astype(np.float)\n",
    "data = MinMaxScaler().fit_transform(data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, classes, test_size=0.2)\n",
    "\n",
    "X_train, X_disc, y_train, y_disc = train_test_split(X_train, y_train, test_size=0.7)\n",
    "\n",
    "data = X_train\n",
    "classes = y_train\n",
    "\n",
    "orig_data = X_test\n",
    "orig_classes = y_test\n",
    "\n",
    "ros = RandomOverSampler()\n",
    "X_resampled, y_resampled = ros.fit_sample(data, classes)\n",
    "\n",
    "#print classes\n",
    "\n",
    "data = X_resampled\n",
    "classes = y_resampled\n",
    "#data = RobustScaler().fit_transform(data)\n",
    "\n",
    "\n",
    "# Random Forest\n",
    "print (\"Random Forest predictions\")\n",
    "feat = 80\n",
    "while(feat < 140):\n",
    "    trees = 100\n",
    "    while(trees < 1000):\n",
    "        clf = RandomForestClassifier(n_estimators=trees, max_features=feat)\n",
    "        clf.fit(data, classes)\n",
    "        rf_pred = clf.predict(orig_data)\n",
    "        kap = coh_kap(orig_classes,rf_pred)\n",
    "        f1 = f1_score(orig_classes,rf_pred,average='weighted')\n",
    "        print (\"RF\\t\"+str(feat)+\"\\t\" +str(trees)+\"\\t\"+str(kap)+\"\\t\"+str(f1))\n",
    "        trees = trees + 200\n",
    "    feat = feat + 10\n",
    "\n",
    "\n",
    "\n",
    "# Neural network\n",
    "#print \"Neural net predictions\"\n",
    "hidden_layer_sizes = [(2048,16),(1024,16),(512,16),(2048,64),(1024,64),(512,64),(2048,128),(1024,128),(512,128)]\n",
    "alp = 0.1\n",
    "while(alp < 5.0):\n",
    "    for hid in hidden_layer_sizes:\n",
    "        clf = MLPClassifier(solver='adam', alpha=alp, hidden_layer_sizes=hid,max_iter=1000)\n",
    "        clf.fit(data, classes)\n",
    "        cnn_pred = clf.predict(orig_data)\n",
    "        kap = coh_kap(orig_classes,cnn_pred)\n",
    "        f1 = f1_score(orig_classes,cnn_pred,average='weighted')\n",
    "        print (\"CNN\\t\"+str(alp)+\"\\t\" +str(hid)+\"\\t\"+str(kap)+\"\\t\"+str(f1))\n",
    "    alp=alp*2.0\n",
    "\n",
    "\n",
    "# SVM params\n",
    "#print \"SVM predictions\"\n",
    "gam = 0.01\n",
    "while(gam < 10.0):\n",
    "    cval = 0.01\n",
    "    while(cval < 10.0):\n",
    "        clf = svm.SVC(kernel='rbf',gamma=gam,C=cval,max_iter=5000)\n",
    "        clf.fit(data, classes)  \n",
    "        svm_pred = clf.predict(orig_data)\n",
    "        kap = coh_kap(orig_classes,svm_pred)\n",
    "        f1 = f1_score(orig_classes,svm_pred,average='weighted')\n",
    "        print (\"SVM\\t\"+str(gam)+\"\\t\" +str(cval)+\"\\t\"+str(kap)+\"\\t\"+str(f1))\n",
    "        cval = cval * 2.0\n",
    "    gam = gam * 2.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
